var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "colophon-1",
  "level": "1",
  "url": "colophon-1.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": "   https:\/\/quaker-ece.cs.earlham.edu\/   https:\/\/quaker-ece.cs.earlham.edu\/     https:\/\/jaorduz.org   https:\/\/jaorduz.github.io   copyright  "
},
{
  "id": "author-bio-TWJ",
  "level": "1",
  "url": "author-bio-TWJ.html",
  "type": "Author Biography",
  "number": "",
  "title": "Author Biography",
  "body": " Dr. Javier Orduz holds the distinguished position of Visiting Assistant Professor at Earlham College and also serves as an Instructor at Baylor University. In his academic course, he embodies an all-rounder that rests on technological expertise with an edge of ambition. Displays of such versatility are echoed in his research, publishing works, teaching style, and foray into deeper areas carried out among friends who share similar interests. A Research Scholar and instructor of Computer Science, he first began his journey at Baylor University in Texas. He moved on from these deep roots to spend more than five years as a postdoctoral scholar and assistant professor of computer science and applied math at the Universidad Nacional Autónoma de México (UNAM).  The impact of Dr. Orduz does not stop in the walls academia And his commitment to the massive potential of quantum computing in Latin America is evident by being at the frontend as the coordinator at He has been unstoppable in driving forward the efforts to bring quantum computing education and research into this vibrant educational ecosystem. As a Research Scientist he tackles forays into quantum machine learning and prepares the future of this field with creative algorithmic solutions. With his mentorship, Dr. Orduz is also dedicated to the community by mentoring and fostering (in multiple ways) the representation of underrepresented cohorts in AI.  "
},
{
  "id": "dedication",
  "level": "1",
  "url": "dedication.html",
  "type": "Dedication",
  "number": "",
  "title": "Dedication",
  "body": "  My family in Colombia, Mexico, and USA.  To people who loves Science.   To all of you.  This is a greate opportunity to encourage to study and learn sciences. In general any field in STEM areas is beatiful!  "
},
{
  "id": "acknowledgement",
  "level": "1",
  "url": "acknowledgement.html",
  "type": "Acknowledgements",
  "number": "",
  "title": "Acknowledgements",
  "body": " This project was supported by the Summer Collaborative Research at Earlhma College.  JO would like to acknowledge the following people for their comments and suggestions.    "
},
{
  "id": "frontmatter-intro",
  "level": "1",
  "url": "frontmatter-intro.html",
  "type": "Section",
  "number": "1",
  "title": "Introduction",
  "body": " Introduction  The word quantum is one that requires particular attention. This word can be used to garner interest, explain physical phenomena, or even just to confuse people. But for physicists, quantum means revolution.  This revolution was born in the early 19th century. New discoveries in physics could not be explained within the classical scientific theories of the time. Scientists needed new ideas to explain atomic and subatomic phenomena.  In the context of quantum computation, the word quantum was coined by theoretical physicist Max Planck during his study of black-body radiation when he proposed the idea that energy was not continuously emitted, but was instead emitted and absorbed in discrete \"quanta\" (a word meaning \"how much\"). This theory allowed him to produce equations that closely matched the observed phenomena around him, solving a problem that physicists had been struggling with for decades. Planck's contributions to science changed our conception of the universe and caused scientists to rethink some of our most fundamental theories. Today, this revolution continues as we discover new advances in the realms of quantum mechanics and quantum computation. Like the scientists of the past, we must question what we know about the world around us to bring this revolution forward into its next steps.  This document contains information about the basics on Quantum Computing. Some concepts require time, in depth analysis, and even the ability to accept counterintuitive ideas.  "
},
{
  "id": "chap1-intro",
  "level": "1",
  "url": "chap1-intro.html",
  "type": "Section",
  "number": "1.1",
  "title": "Introduction",
  "body": " Introduction  In this chapter, we shall discuss physics and its role in quantum computing Quantum Quantum Computing . It will be particularly relevant for people who think the study of physics and mathematics is nothing more than a list of equations to memorize for any undergraduate student enrolled in sciences. This is untrue. Science evolves every day and the job of a scientist is to synthesize their knowledge to face problems and find solutions. Since physics is relevant to many different domains in science, it is a multifaceted subject that is highly important to study.  Physics is about motion, atoms, nuclei, elementary particles, heat, Thermodynamics, Electrodynamics, and Statistics, among other areas. These many different fields can be classified by their mathematical concepts, their chronological development, or even in terms of theoretical and experimental scientific points of view.  One of the most important branches of Physics studies interaction at tiny scale: Quantum Mechanics. This branch was revolutionized by Max Planck in the early 1900s, although many other scientists contributed to its development. The phenomena that Planck and other scientists observed at this tiny scale were at odds with the scientific \"rules\" established by Classical Physics. To resolve this issue, the field of Quantum Mechanics was born to provide an explanation for subatomic phenomena. This field established non-conventional concepts that have quickly spread throughout other realms of science. In the coming chapters we will discuss the mathematical foundations of Quantum Mechanics.  "
},
{
  "id": "p-12",
  "level": "2",
  "url": "chap1-intro.html#p-12",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "quantum computing "
},
{
  "id": "Classical-Physics",
  "level": "1",
  "url": "Classical-Physics.html",
  "type": "Section",
  "number": "1.2",
  "title": "Classical Physics",
  "body": " Classical Physics  Classical physics, a cornerstone of scientific understanding, encompasses several branches that describe the physical phenomena of the universe, laying the groundwork for modern science. Optics, electromagnetism, nuclear physics, astrophysics, and thermodynamics are pivotal fields that have evolved through centuries of inquiry and discovery. Optics, the study of light and its interactions with matter, dates back to ancient civilizations. The Greeks, particularly Euclid and Ptolemy, made early contributions with theories on reflection and refraction.  In the 17th century, Johannes Kepler elucidated the principles of lenses and vision, while Galileo's telescopic observations expanded our understanding of the cosmos. Isaac Newton's corpuscular theory of light and Christian Huygens' wave theory were significant milestones, reconciled in the 19th century by experiments demonstrating the wave nature of light.  Electromagnetism, dealing with electric and magnetic fields and their interactions, began in the 18th century with static electricity and magnetism as separate phenomena. Benjamin Franklin's experiments with lightning and Luigi Galvani's work on bioelectricity were early milestones. The unification of electricity and magnetism into a single theory was achieved by James Clerk Maxwell in the mid-19th century, whose equations predicted the existence of electromagnetic waves, leading to Heinrich Hertz's discovery of radio waves.  Nuclear physics, focusing on atomic nuclei, emerged in the early 20th century, building on classical foundations. The discovery of radioactivity by Henri Becquerel and the subsequent work of Marie and Pierre Curie opened new frontiers. Ernest Rutherford's gold foil experiment, which revealed the nucleus of an atom, was pivotal. Early developments in nuclear decay laws and the identification of radiation types owe much to classical methodologies.  Astrophysics, applying physics to celestial objects and phenomena, has ancient origins in observational astronomy. Early contributions by Hipparchus and Ptolemy laid the groundwork, but the Copernican Revolution in the 16th century and Johannes Kepler's laws of planetary motion advanced the field. Newton's law of universal gravitation unified terrestrial and celestial mechanics under a single theory, revealing that the force that moved the stars was the same one that held us to the ground: gravity.  Thermodynamics, the study of heat, work, and energy, emerged from the Industrial Revolution's practical needs. Sadi Carnot's work on steam engines laid the foundation for the field. The first and second laws of thermodynamics, formulated by Rudolf Clausius and William Thomson (Lord Kelvin), established principles governing energy conservation and entropy, profoundly influencing scientific thought and engineering practice.  Classical physics is crucial academically as it forms the foundational bedrock upon which modern physics and other scientific disciplines are built. It introduces students to fundamental concepts such as Newtonian mechanics, thermodynamics, and electromagnetism, cultivating critical thinking and problem-solving skills. Mastery of classical physics fosters an appreciation for the scientific method and the historical context of discoveries, illustrating the interplay of theoretical advances and experimental validations. Serving as an indispensable educational foundation, classical physics equips students with the knowledge and skills necessary for careers in science, engineering, and technology, continuing to inspire future innovations and discoveries.  "
},
{
  "id": "Newtonian-Mechanics",
  "level": "1",
  "url": "Newtonian-Mechanics.html",
  "type": "Section",
  "number": "1.3",
  "title": "Newtonian Mechanics",
  "body": " Newtonian Mechanics  Many of the concepts behind Classical Physics are motivated by Newtonian Mechanics, which is derived from Newton’s three laws of motion. These laws provide a framework for determining how an object will move when acted upon (or not acted upon) by external forces. Newton’s three laws were first described in his Philosophiæ Naturalis Principia Mathematica , which is widely considered to be one of the most important works in the history of physics.   Newton’s first law, put simply, is that in the absence of external forces, an object at rest will stay at rest and an object in motion will stay in motion. Furthermore, without outside interference, an object in motion will travel at a constant speed in a straight line. In Principia , Newton defines inertia as the property of matter to preserve its current state and resist attempts to change it. Thus, the first law of motion establishes that all objects have the property of inertia and resist changes to their state of rest or motion.  The second law of motion is often abbreviated by the equation This equation tells us that the acceleration ( ) of an object is directly proportional to the net force ( ) acting upon it and is inversely proportional to the mass ( ) of the object. Mass can be thought of as a numerical measure of inertia, so the second law relates to the first law in that objects with a lot of mass, i.e. objects with a lot of inertia, require greater forces to accelerate. Furthermore, if we look at the case where there are no forces acting upon an object, i.e. , we know that as well. Since the mass of an object can never be , when there are no forces acting upon an object, it must have an acceleration of . In the absence of acceleration, an object at rest will stay at rest and an object in motion will continue to travel at a constant speed.  Newton’s third law states that when two objects interact, the force exerted by the first object on the second is equal in magnitude and opposite in direction to the force exerted by the second object on the first. Simply put, every action has an equal and opposite reaction.  The three laws of motion can be seen in the example of a rocket launching into space. As the thrusters begin to fire, the rocket does not immediately begin to move. Since the rocket begins at rest, its inertial properties resist changing to a state of motion, which showcases the first law. Once the rocket begins to lift off the ground, it appears to be moving upwards slowly. Since the rocket is very heavy, it has a lot of mass, and since acceleration is inversely proportional to mass by Newton’s second law, it thus accelerates slowly. The third law of motion can be seen in the fact that the rocket engines are pushing down, which causes the equal and opposite reaction of the rocket to move upwards.     "
},
{
  "id": "activity-1",
  "level": "2",
  "url": "Newtonian-Mechanics.html#activity-1",
  "type": "Activity",
  "number": "1.3.1",
  "title": "",
  "body": "  "
},
{
  "id": "Classical-Computing",
  "level": "1",
  "url": "Classical-Computing.html",
  "type": "Section",
  "number": "1.4",
  "title": "Classical Computing",
  "body": " Classical Computing  Before diving into the basics of quantum computing, we must first discuss how computing is done classically. On non-quantum computers, information is stored in strings of bits, where each bit is either a 0 or a 1. These strings of bits represent numbers in binary and they provide computers with instructions on what to do. The notable difference on a quantum computer is that quantum bits (qubits) exist in a superposition Superposition of states that allows them to be both a 0 and a 1 until they are measured and this superposition collapses. This unique property of qubits allows quantum computers to perform multiple processes simultaneously.  When describing the state of a qubit, instead of writing 0 and 1, we use and . These quantum states belong to a vector space Vector Vector Space , which means that multiplying states by a constant coefficient and adding states together will result in another valid quantum state. This is how a superposition is formed, by creating a linear combination of the states and .  "
},
{
  "id": "p-27",
  "level": "2",
  "url": "Classical-Computing.html#p-27",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "superposition "
},
{
  "id": "p-28",
  "level": "2",
  "url": "Classical-Computing.html#p-28",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "vector space "
},
{
  "id": "Vectors-and-Vector-Spaces",
  "level": "1",
  "url": "Vectors-and-Vector-Spaces.html",
  "type": "Section",
  "number": "1.5",
  "title": "Vectors and Vector Spaces",
  "body": " Vectors and Vector Spaces   Introduction to Vectors  A vector is an ordered list of numbers that is used to describe quantities with both magnitude and direction. One example of a vector is force, which has both a magnitude (how strong the force is) and a direction (the angle at which the force is being applied). Each vector has a dimension, which is the number of components that comprise it. It is customary to signify that something is a vector by either drawing an arrow on top of it or bolding it. If we have a vector called , we would write or . The number is called the -th component of .  The most typical use of a vector with components is to describe a point in dimensional space in reference to some starting point. For example, if you have a square piece of paper and label the bottom left corner with the starting point (0,0), then a vector with components (1,1) would represent moving one unit of measurement along the bottom of the paper and one unit of measurement along the side of the paper to reach a new point. This vector would have a direction of and a magnitude of units (by the pythagorean theorem).   An example of a vector     Vector Spaces  Every vector exists within a vector space Vector Vector Space , which are sets that satisfy certain mathematical properties. The most common vector spaces we will deal with are , the set of all dimensional vectors with real components, and , the set of all dimensional vectors with complex components. Notice , so we will usually work with for generality. All vector spaces have the same properties regardless of dimension. Here are the properties for an -dimensional vector space:  1. Vector equality: means   2. Vector addition: means   3. Scalar multiplication:   4. Negative of a vector:   5. Null vector: There exists a null vector   If our vector components are all real numbers (i.e. the vector space exists in instead of ), then the following properties also hold:  1. Addition of vectors is commutative:  2. Addition of vectors is associative:  3. Scalar multiplication is distributive: and  4. Scalar multiplication is associative:     Bases  For any vector space, one can find a subset of vectors which can be used to generate any other vector in the space through linear combinations (scalar multiplication and vector addition). The smallest set of vectors that fulfills this property is called the basis Vector basis . In , we only need two vectors to produce the rest through linear combination. The standard basis, is:   The ^ symbol is used to denote that a vector is normal Vector Normal , which means that it has a length of 1. The vector is referred to as \" hat.\" This property is extremely important to quantum mechanics and will be discussed more later.  Bases have two properties:   Linear Independence: A set of vectors is linearly independent Vector Linearly Independent if we cannot express any one of them as a linear combination of the others. If we can express one as a linear combination of the others, then it is called a linearly dependent Vector Linearly Dependent set. A basis must be linearly independent.   Completeness: A set of vectors is complete if it spans Vector Span its vector space, which in turn means that any vector in the space can be expressed as a linear combination of the vectors in that set. A basis for a vector space must span the space.    (A Counterexample)  Let be the set,   And let be the vector,   Since we are unable to express as a linear combination of the elements of , then we say is not complete.    Let be the set,   And let be the vector,  We can express as:  Since we can express as a linear combination of the elements of and it is easy to show that we could construct any other vector in from these same elements, we say that spans and is complete.   Dimension of a basis. The number of basis elements for a vector space is the same as that spaces dimension.   Linear Algebra  Linear algebra is the study of vectors and transformations. In this subsection we will describe some other pieces of linear algebra that will be important to quantum computation.  Vector Transpose: The transpose Vector Transpose is an operation that turns a standard column vector into a row vector, or vice versa. This means an dimensional vector changes from having rows and column to having row and columns. The transpose is represented with a superscript and the operation is shown below.   Dot Product \/ Inner Product: The dot product (more generally known as the inner product Vector Inner Product in the context of quantum computation) is an operation between two vectors of the same dimension that produces a scalar. This product is typically referred to with a , but has an alternate notation in quantum computation that we will see in the next section. In and In this operation is performed by taking the sum of the products of the corresponding entries in each vector, as shown below.      Find the inner product     Orthogonality:  Orthogonality Orthogonality is the generalization of the concept of perpendicularity. In two and three dimensional space, two vectors are orthogonal if the angle between them is a right angle. Two vectors are orthogonal if their inner product is equal to .  Are the following vectors orthogonal?  Yes, Since the inner product between the two vectors is 0, they are orthogonal  Normality: A vector is normal Vector Normal Vector if it has a length of . The length (sometimes also referred to as the norm) of a vector can be found be taking the square root of the sum of the squares of its entries, as shown below. This operation is represented by lines( ) on either side of the vector that is having its length found. A non-normal vector can be normalized by dividing each of its components by the vectors length. A normalized vector has the same direction as the original vector, but has a length of . A set of vectors is orthonormal Vector Orthonormal Vectors if each of the vectors are normal and each of the vectors are orthogonal to the rest.   What is the length of the following vector?    Normalize the following vector In the previous exercise, we found that this vector has a length of . To normalize the vector, we will divide each of its components by its length.   Matrices: Whereas a vector is a single column of elements, a matrix Matrix is a table of elements organized in rows and columns. Technically speaking, a vector can be thought of a matrix with only one column. The dimension of a matrix is described by first listing the number of rows and then listing the number of columns. Thus, a matrix (read \"two by three\") would have two rows and three columns. A square matrix Matrix Square Matrix is any matrix with the same number of rows and columns. One of the most important matrices is the identity matrix Matrix Identity Matrix , a square matrix in which all of the entries along the diagonal are and all other entries are . Examples of the and identity matrices are shown below, which can be generalized to any matrix.   A matrix can be multiplied by a scalar in the same way that a vector can, by multiplying each entry in the matrix by the scalar, as shown below.   The concept of a transpose can be extended from vectors to matrices as well. A matrix's transpose is found by turning each of its rows into a column, or, equivalently, by turning each of its columns into a row. This means the transpose of an matrix is an matrix. The matrix transpose is also represented by a superscript . An example of transposing a matrix is shown below.   Matrix Addition: Two matrices can be added together only if they each have the same number of rows and columns. The sum of two matrices is found by adding together the corresponding entries of each matrix, as shown below with an example of two matrices.    Compute the following sum:      Matrix Multiplication: Two matrices can be multiplied together only if the number of columns of the left matrix is equal to the number of rows of the right matrix. The resulting product will be a matrix with the same number of rows as the left matrix and the same number of columns as the right. Thus an matrix multiplied by a matrix would produce an matrix. Notably, matrix multiplication is non-commutative, which means for two matrices and , . The entries of a product matrix are determined by taking the dot product between the corresponding row of the left matrix and the corresponding column of the right matrix, as shown below with an example of multiplication between a and a matrix.   Now that we know matrix multiplication, we can redefine the dot product \/ inner product as the transpose of a vector multiplied by the original vector. Since vectors are dimensional, the transpose will be dimensional, so multiplying the transpose on the left and the original on the right will produce a matrix, which is functionally the same as a scalar.  Multiplying an matrix by a vector produces an vector. This operation is known as a linear transformation Linear Transformation and it an be used to move vectors from one vector space to another.   Compute the following product:    The resulting matrix should be     Determinant: The determinant Determinant is a scalar associated with a square matrix that can be used to find the eigenvalues (see ) of the matrix. For and matrices, their determinants are defined as follows:      Eigenvectors and Eigenvalues  Here we will provide a brief overview of eigenvectors and eigenvalues, but readers wishing to learn more should go to this link . An eigenvector of a matrix is a non-zero vector such that   where v is a scalar known as the eigenvalue of corresponding to . It will often be convenient to use the variable both as a label for the eigenvector, and to represent the eigenvalue. The eigenvalues of a matrix can be found by solving the equation   In this equation, is an unknown variable whose values we want to find. These values will be the eigenvalues of the matrix . Each eigenvalue will have a corresponding eigenvector such that . The corresponding eigenvectors can then be found by solving   The eigenspace corresponding to an eigenvalue is the set of vectors which have eigenvalue . It is a vector subspace of the vector space on which acts. The eigenspace corresponding to the matrix would be all vectors that have an eigenvalue for that matrix.   "
},
{
  "id": "p-31",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-31",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "vector space "
},
{
  "id": "p-42",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-42",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "basis "
},
{
  "id": "p-43",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-43",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "normal "
},
{
  "id": "p-45",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-45",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "linearly independent linearly dependent "
},
{
  "id": "p-46",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-46",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "spans "
},
{
  "id": "example-1",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#example-1",
  "type": "Example",
  "number": "1.5.1",
  "title": "(A Counterexample).",
  "body": " (A Counterexample)  Let be the set,   And let be the vector,   Since we are unable to express as a linear combination of the elements of , then we say is not complete.  "
},
{
  "id": "example-2",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#example-2",
  "type": "Example",
  "number": "1.5.2",
  "title": "",
  "body": " Let be the set,   And let be the vector,  We can express as:  Since we can express as a linear combination of the elements of and it is easy to show that we could construct any other vector in from these same elements, we say that spans and is complete.  "
},
{
  "id": "thm-1",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#thm-1",
  "type": "Theorem",
  "number": "1.5.3",
  "title": "",
  "body": "Dimension of a basis. The number of basis elements for a vector space is the same as that spaces dimension. "
},
{
  "id": "p-55",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-55",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "transpose "
},
{
  "id": "p-56",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-56",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "inner product "
},
{
  "id": "example-3",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#example-3",
  "type": "Example",
  "number": "1.5.4",
  "title": "",
  "body": "  "
},
{
  "id": "exercise-1",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-1",
  "type": "Checkpoint",
  "number": "1.5.5",
  "title": "",
  "body": "Find the inner product    "
},
{
  "id": "p-58",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-58",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Orthogonality "
},
{
  "id": "exercise-2",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-2",
  "type": "Checkpoint",
  "number": "1.5.6",
  "title": "",
  "body": "Are the following vectors orthogonal?  Yes, Since the inner product between the two vectors is 0, they are orthogonal "
},
{
  "id": "p-62",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-62",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "normal orthonormal "
},
{
  "id": "exercise-3",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-3",
  "type": "Checkpoint",
  "number": "1.5.7",
  "title": "",
  "body": "What is the length of the following vector?   "
},
{
  "id": "exercise-4",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-4",
  "type": "Checkpoint",
  "number": "1.5.8",
  "title": "",
  "body": "Normalize the following vector In the previous exercise, we found that this vector has a length of . To normalize the vector, we will divide each of its components by its length.  "
},
{
  "id": "p-66",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-66",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "matrix square matrix identity matrix "
},
{
  "id": "exercise-5",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-5",
  "type": "Checkpoint",
  "number": "1.5.9",
  "title": "",
  "body": " Compute the following sum:     "
},
{
  "id": "p-73",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-73",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "linear transformation "
},
{
  "id": "exercise-6",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#exercise-6",
  "type": "Checkpoint",
  "number": "1.5.10",
  "title": "",
  "body": " Compute the following product:    The resulting matrix should be    "
},
{
  "id": "p-76",
  "level": "2",
  "url": "Vectors-and-Vector-Spaces.html#p-76",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "determinant "
},
{
  "id": "Linear-Algebra-in-Quantum-Computation",
  "level": "1",
  "url": "Linear-Algebra-in-Quantum-Computation.html",
  "type": "Section",
  "number": "1.6",
  "title": "Linear Algebra in Quantum Computation",
  "body": " Linear Algebra in Quantum Computation  As mentioned in the section on Classical Computing , qubits can be in the state or . What's more, these states can be represented with vectors.   and   This notation was first introduced by mathematician Paul Dirac and is known as \"Dirac Notation\" or \" Bra-Ket Notation Bra-Ket Notation .\" In this notation, the symbol represents a qubit state and is referred to as a \" ket Bra-Ket Notation Ket .\" At a glance, it can be seen that the vectors and are each normal and are orthogonal to each other. Additionally, any point in two dimensional space could be described with a linear combination of these two vectors, meaning they form a basis (we will discuss exactly which space they form a basis for in the following section). Put together, this means and form an orthonormal basis. All qubits must be normalized in order to be expressed properly.  Systems with multiple qubits are described by vectors in higher dimensions, which will be discussed later.  "
},
{
  "id": "p-83",
  "level": "2",
  "url": "Linear-Algebra-in-Quantum-Computation.html#p-83",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Bra-Ket Notation ket "
},
{
  "id": "Qubit-States",
  "level": "1",
  "url": "Qubit-States.html",
  "type": "Section",
  "number": "1.7",
  "title": "Qubit States",
  "body": " Qubit States   Qubits  As a reminder, a qubit exists in a superposition between the states and , which means that they can be expressed as a linear combination of the vectors and . This means a qubit can be expressed   Where and are complex coefficiants that relate to the probability that a qubit is in the states and respectively. This means that qubits exist within a complex vector space. The exact space that qubits exist within is known as a hilbert Space Hilbert Space .    Hilbert Space  A hilbert space is a complex vector space in which the inner product is defined as an operation. A single qubit exists within the hilbert space , which is the set of all two dimensional vectors with complex entries.    Bra Vectors and the Inner Product for Quantum Computation  We now introduce the bra in Bra-Ket Notation. Each vector representation of a qubit has a corresponding bra Bra-Ket Notation Bra vector (sometimes also referred to as the \"Dual Vector\") that is equal to the complex conjugate of the transpose of the ket. This operation of taking the transpose and complex conjugating is known as the adjoint Adjoint and is represented by the symbol. Bra vectors are represented by the symbol . An example of finding the bra vector for the ket is shown below (where the symbol represents complex conjugating).   Bra vectors allow us to use a new notation for the inner product. We write the inner product between two vectors, and , as and perform the calculation as matrix multiplication, as described in   Find the inner product between the following two qubits.       Qubit Measurements  When a qubit is measured, it collapses from being a superposition of the states and to being in one state or the other. The probability that the qubit will be in either state is related to the coefficient on that state. Consider a qubit ,   Since all qubits are normalized, has a length of , so , which means . Since the combined probability that the qubit will be in the state or is equal to , we use the normal property of qubits as a method to determine the probability that the qubit will be in either state. For the qubit the probability that it will be in the state after it is measured is and the probability that it will be in the state is .  Born Rule: The Born Rule tells us that if we express a qubit as a linear combination of basis states, then upon measurement, the probability that the qubit collapses into any given basis state is equal to the square of the coefficient for that basis state. A qubit in a vector space defined by the basis    The probability that will collapse into the basis state is given by . Furthermore, since qubits are normalized   For the following qubit, find the probability that it will be in the state and the probability that it will be in the state after measurement  The probability that will be in the state after measurement is 25% because . The probability that will be in the state after measurement is 75% because .  Another way to find the probability that a qubit is in any given state is to take the square of the inner product of the outcome state and the qubit. For a qubit , the probability that it is in the state after measurement would be , the probability that it is in the state would be , and the probability that it is in some mixed state would be .  Using an inner product, calculate the probability that the following system is in the state and .    The probability that will collapse into the state is 87.5%.   The probability that will collapse into the state is 12.5%.    "
},
{
  "id": "p-86",
  "level": "2",
  "url": "Qubit-States.html#p-86",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "hilbert Space "
},
{
  "id": "p-88",
  "level": "2",
  "url": "Qubit-States.html#p-88",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "bra adjoint "
},
{
  "id": "exercise-7",
  "level": "2",
  "url": "Qubit-States.html#exercise-7",
  "type": "Checkpoint",
  "number": "1.7.1",
  "title": "",
  "body": "Find the inner product between the following two qubits.    "
},
{
  "id": "exercise-8",
  "level": "2",
  "url": "Qubit-States.html#exercise-8",
  "type": "Checkpoint",
  "number": "1.7.2",
  "title": "",
  "body": "For the following qubit, find the probability that it will be in the state and the probability that it will be in the state after measurement  The probability that will be in the state after measurement is 25% because . The probability that will be in the state after measurement is 75% because . "
},
{
  "id": "exercise-9",
  "level": "2",
  "url": "Qubit-States.html#exercise-9",
  "type": "Checkpoint",
  "number": "1.7.3",
  "title": "",
  "body": "Using an inner product, calculate the probability that the following system is in the state and .    The probability that will collapse into the state is 87.5%.   The probability that will collapse into the state is 12.5%.  "
},
{
  "id": "Computational-Bases",
  "level": "1",
  "url": "Computational-Bases.html",
  "type": "Section",
  "number": "1.8",
  "title": "Computational Bases and the Bloch Sphere",
  "body": " Computational Bases and the Bloch Sphere  So far, the only basis we have looked at for measuring a qubit is , but this is not the only one. In quantum computation, we define three orthogonal basis states. For now, we will call these the X-measurement, Y-measurement, and Z-measurement, which will make sense shortly.  X-Measurement   are eigenstates of the Pauli X Matrix, (which is , as we will see in ). These are called the Hadamard (transversal) basis states   Y-Measurement  are eigenstates of the Pauli Y Matrix, (which is , as we will see in ).These are called the Longitudinal (Left-Right) basis states   Z-Measurement   are eigenstates of the Pauli Z Matrix, (which is , as we will see in ). These are called the Computational basis states   A state in the Hadamard basis  is measured in the basis Calculate and      A state in the Computational basis  is measured in the basis Calculate and .      The Bloch Sphere  Recall that any qubit can be written as and . Because of this bounding property, we can say there exist some real numbers such that   Since the is simply a scalar applied to the entire system, it will have no observable effect on the state of the system. This means we can ignore that term, leaving us with   The numbers and define a point on the three-dimensional unit sphere, which we will here call the Bloch sphere Bloch Sphere . The Bloch sphere exists within a Hilbert Space, , and provides an intuitive method for depicting qubits as vectors and visualizing the operations we can perform on them.   The Bloch sphere and the representation of a qubit with angle along the horizontal plane and angle along the vertical axis, as well as the computational basis vectors.     One quirk of the Bloch sphere is that any two orthogonal state vectors (qubits) are represented on the sphere not as perpendicular, but as two vectors along the same line pointing in opposite directions. Thus the x-axis is defined by in the positive direction and in the negative direction, the y-axis is defined by in the positive and in the negative, and the z-axis is defined by in the positive and in the negative, hence the reason for the names of these states.  Those familiar with multivariate calculus will know that any point on the surface of the unit sphere can be described with the vector   If we choose , we obtain   which corresponds to on the Block sphere.  If we choose . we obtain   which corresponds to on the Block sphere. This is our reason for choosing to use as an angle in our definition of the block instead of just using . When ,   and when and ,    Using the vector equation for points on the surface of the unit sphere, consider the following values:  1. and Obtain  2. and Obtain  3. and Obtain   4. and Obtain    The Bloch sphere is called a projective sphere because the states of our quantum system are rays in the Hilbert space , and we would prefer to visualize vectors as points, not rays. Going back to the underlying we collapse the ray that represents a quantum state onto the surface of an -dimensional sphere. We are projecting all those representatives onto a single point on the complex n-sphere. Notice that each point on that sphere still has infinitely many representations impossible to picture due to the potential scalar factor , that we left out of our equation.  The Pauli gates and (which we will see in ) correspond to rotations about the and axes of the Bloch sphere   "
},
{
  "id": "exercise-10",
  "level": "2",
  "url": "Computational-Bases.html#exercise-10",
  "type": "Checkpoint",
  "number": "1.8.1",
  "title": "A state in the Hadamard basis.",
  "body": "A state in the Hadamard basis  is measured in the basis Calculate and     "
},
{
  "id": "exercise-11",
  "level": "2",
  "url": "Computational-Bases.html#exercise-11",
  "type": "Checkpoint",
  "number": "1.8.2",
  "title": "A state in the Computational basis.",
  "body": "A state in the Computational basis  is measured in the basis Calculate and .    "
},
{
  "id": "p-112",
  "level": "2",
  "url": "Computational-Bases.html#p-112",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Bloch sphere "
},
{
  "id": "fig-Bloch-Sphere",
  "level": "2",
  "url": "Computational-Bases.html#fig-Bloch-Sphere",
  "type": "Figure",
  "number": "1.8.3",
  "title": "",
  "body": " The Bloch sphere and the representation of a qubit with angle along the horizontal plane and angle along the vertical axis, as well as the computational basis vectors.    "
},
{
  "id": "exercise-12",
  "level": "2",
  "url": "Computational-Bases.html#exercise-12",
  "type": "Checkpoint",
  "number": "1.8.4",
  "title": "",
  "body": " Using the vector equation for points on the surface of the unit sphere, consider the following values:  1. and Obtain  2. and Obtain  3. and Obtain   4. and Obtain   "
},
{
  "id": "Operators",
  "level": "1",
  "url": "Operators.html",
  "type": "Section",
  "number": "1.9",
  "title": "Operators",
  "body": " Operators  In physics, things we are able to measure are called observables Observables . Examples of observables are things like position, momentum, and energy, among many others. Any observables that relate to the quantum state of a particle have a corresponding operator Operator . Operators are used to map vectors from one vector space onto another. An operator that maps from a vector space to a vector space could be written as . In quantum computation, operators act on kets from the left side and on bras from the right side. For a ket and a bra , an operator would act on them as follows   Consider that is not a scalar, but rather an operator maps between vector spaces, which means that these equations do not just represent basic multiplication. In quantum theory, operators can be represented by matrices, and tools like matrix multiplication and matrix addition (see ) can be used to perform operations on qubits.   Hermitian Operators  Recall from that the adjoint operation represented by the symbol consisted of transposing and complex conjugating a vector. This same operation can be performed on an operator (note that operations and operators are two different things). An operator is Hermitian Operator Hermitian Operator (also referred to as adjoin) if it satisfies the following property:   Other properties of Hermitian operators are  Noncommutative   Associative (multiplicative)   Hermitian Product   Linear An operator takes a vector and transforms it into a new vector . If is a linear operator, then   where and    Which of the following operators are Hermitian?       1.   Since this matrix equals its adjoint, it is Hermitian  2.   Since this matrix equals its adjoint, it is Hermitian  3.   Since this matrix does not equal its adjoint, it is not Hermitian  4.   Since this matrix equals its adjoint, it is Hermitian     Unitary Operators  Recall that for a qubit the property must hold. After an operator is applied to this qubit, we get a new state defined by   If the property that still holds, then the operator is unitary Operator Unitary Operator . Unitary operators map qubits between Hilbert spaces. A unitary operator , could be defined as . A defining property of unitary operators is   where is the identity matrix.  Unitary operations performed on a qubit are reversible. This means that for an operator that acts on a qubit such that , there exists some operator such that . This is called the inverse of . Inverse matrices have the property that   This means that for Unitary operators, the following property holds:     Additional Properties and Other  Recall from that operators work on a ket from the left side and on a bra from the right side. Additionally, recall   For an operator acting on a ket , the adjoint is   and is another operator.   That is the extent to which we will discuss operators in this webbook, but readers wishing to extend their knowledge should go to this document   Below is pictured a circuit diagram (which we will delve deeper into in ) representing the action on a single Qbit of the 1-Qbit gate . Initially the Qbit is described by the input state on the left of the line. The line (wire) represents the subsequent operation on the Qbit. After emerging from the box representing the operator , the Qbit is described by the final state     "
},
{
  "id": "p-127",
  "level": "2",
  "url": "Operators.html#p-127",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "observables operator "
},
{
  "id": "p-129",
  "level": "2",
  "url": "Operators.html#p-129",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Hermitian "
},
{
  "id": "exercise-13",
  "level": "2",
  "url": "Operators.html#exercise-13",
  "type": "Checkpoint",
  "number": "1.9.1",
  "title": "",
  "body": " Which of the following operators are Hermitian?       1.   Since this matrix equals its adjoint, it is Hermitian  2.   Since this matrix equals its adjoint, it is Hermitian  3.   Since this matrix does not equal its adjoint, it is not Hermitian  4.   Since this matrix equals its adjoint, it is Hermitian  "
},
{
  "id": "p-147",
  "level": "2",
  "url": "Operators.html#p-147",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "unitary "
},
{
  "id": "sec-Systems-of-Multiple-Qubits",
  "level": "1",
  "url": "sec-Systems-of-Multiple-Qubits.html",
  "type": "Section",
  "number": "1.10",
  "title": "Systems of Multiple Qubits",
<<<<<<< HEAD
  "body": " Systems of Multiple Qubits  Any system of qubits will have basis states. As we have seen already, in a one-qubit system, the two basis states are and . In a two-qubit system, the four basis states are , , , and . These four basis states each have vector representations, which are found by using the tensor product Tensor Product    Tensor Product  The tensor product (represented by a symbol) is an operation between two matrices (or vectors) that multiplies each entry in the matrix on the left by the matrix on the right. Thus the tensor product between a matrix and a matrix will be a , as shown below.   where each is the entry in the -th row and -th column of .  For scalars and vectors the tensor product can be distributed as follows   Computer the following tensor products        Systems of Multiple Qubits  The vector representation of a two qubit system would be found by the tensor product . Thus the four basis states of a two qubit system are defined as:      This concept can be generalized to systems of any number of qubits. A system of two qubits is referred to as bipartite Bipartite or composite.  The tensor product can also be applied to vector spaces. The tensor product of a vector that exists within a space and a vector that exists within a space would exist within the space . Thus, a system of two qubits would exist within the space and a system of qubits exists within the space , where the superscript means taking the tensor product of with itself times. Similarly, would represent the state tensored with itself times. Suppose the space is dimensional the space is dimensional, then the vector space would be dimensional.     Suppose, we have two vector spaces and and we want to know what kind of operator act on the space . If is an operator on the space and is an operator on the space , then is an operator on the space . An operator is linear if   For and .  For the two qubit system compute the probabilities that it will collapse into each the basis states , , , and        Compute         "
=======
  "body": " Systems of Multiple Qubits  Any system of qubits will have basis states. As we have seen already, in a one-qubit system, the two basis states are and . In a two-qubit system, the four basis states are , , , and . These four basis states each have vector representations, which are found by using the tensor product Tensor Product    Tensor Product  The tensor product (represented by a symbol) is an operation between two matrices (or vectors) that multiplies each entry in the matrix on the left by the matrix on the right. Thus the tensor product between a matrix and a matrix will be a , as shown below.   where each is the entry in the -th row and -th column of .  Computer the following tensor products        Systems of Multiple Qubits  The vector representation of a two qubit system would be found by the tensor product }. Thus the four basis states of a two qubit system are defined as:      This concept can be generalized to systems of any number of qubits.  The tensor product can also be applied to vector spaces. The tensor product of a vector that exists within a space and a vector that exists within a space would exist within the space . Thus, a system of qubits exists within the space , where the superscript means taking the tensor product of with itself times. Similarly, would represent the state tensored with itself times.  For the two qubit system compute the probabilities that it will collapse into each the basis states , , , and         "
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
},
{
  "id": "p-158",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#p-158",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "tensor product "
},
{
  "id": "exercise-14",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#exercise-14",
  "type": "Checkpoint",
  "number": "1.10.1",
  "title": "",
  "body": "Computer the following tensor products     "
},
{
<<<<<<< HEAD
  "id": "p-164",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#p-164",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "bipartite "
},
{
  "id": "example-4",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#example-4",
  "type": "Example",
  "number": "1.10.2",
  "title": "",
  "body": "  "
},
{
=======
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "id": "exercise-15",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#exercise-15",
  "type": "Checkpoint",
<<<<<<< HEAD
  "number": "1.10.3",
=======
  "number": "1.10.2",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "title": "",
  "body": "For the two qubit system compute the probabilities that it will collapse into each the basis states , , , and       "
},
{
<<<<<<< HEAD
  "id": "exercise-16",
  "level": "2",
  "url": "sec-Systems-of-Multiple-Qubits.html#exercise-16",
  "type": "Checkpoint",
  "number": "1.10.4",
  "title": "",
  "body": "Compute       "
},
{
=======
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "id": "sec-Operations",
  "level": "1",
  "url": "sec-Operations.html",
  "type": "Section",
  "number": "1.11",
  "title": "Operations in Quantum Computation",
  "body": " Operations in Quantum Computation   Outer Product  The tensor product is only one of many operations on qubits. In we described how the inner product could be represented as the product of a vector's transpose and the vector. Since an dimensional vector transpose is and the vector is , the resulting product is , which is functionally equivalent to a scalar. If we were to reverse the order of the vector multiplication and multiply a column vector on the left and a row vector on the right, we would multiply an vector by an vector to produce an matrix. More specifically, we want to multiply a vector on the left by the vectors adjoint (complex conjugated transpose) on the right. This operation is known as the outer product Outer Product . The outer product between two qubits and is shown below.      Completeness Relation  If a set of basis vectors for a quantum system have the property that the sum of the outer products of each basis vector with itself is equal to the identity matrix:   Then that set is said to have a completeness relation Completeness Relation . In general, orthonormal bases will have a completeness relation. Since the completeness relation is the same as the identity operator, we can use it on any vector expression without changing its value.  Suppose is a vector in a space and is an orthonormal basis of with a completeness relation. We can then use the completeness relation as follows   Where each and represents the component of the vector that is in the direction of the basis . Thus the completeness relation can be used to decompose a vector into its basis elements.    Inner Product  Here we will redefine the inner product in Bra-Ket notation and describe some additional properties. For two qubits and    their inner product   We now define   We call , the Kronecker delta. It is the mathematical way to express anything that is equal to 0 unless the index , in which case it is 1. For an orthonormal basis we have the property   That is, for any two vectors in the basis, their inner product is 0, unless the two vectors are the same, in which case their inner product is 1.  For and , the inner product has the following properties:     Diagonalization  For a vector space with a basis , A diagonal representation for an operator that acts on the space would be where the are eigenvalues that correspond to the basis state . An operator is said to be diagonalizable Diagonalizable if it has a diagonal representation. As an example of a diagonal representation, note that the Pauli matrix (see ) may be written   where . Diagonal representations are sometimes also known as orthonormal decompositions.    Density Operator  Any basis state for a vector space can also be expressed with a density operator Density Operator that provides us with another method to study the state of the entire system. For a vector space with a basis , the density operators for its basis states are given by   This means that the density operator for any basis state is equal to the outer product of that state with itself. These density operators for states have the following properties:   For a state   The density operator would be    Find the density operator for the following state       Now suppose we want to find a density operator for an entire system. The system exists within a vector space with a basis and has a probability of being in the state after measurement. The density operator for the entire system is defined by   The density operator for the system has the same properties as the density operator for individual states: Idempotent, Trace=1, Hermiticity, and Positive Semi-Definite.    The Commutator  Remember that matrix multiplication is generally not commutative, i.e. for two matrices and , . However, there are exceptions to this generality. The commutator Commutator between two operators and is defined to be   If , that is, , then we say commutes with . Similarly, the anti-commutator Anti-Commutator of two operators and is defined by   we say anti-commutes with if , that is . It turns out that many important properties of pairs of operators can be deduced from their commutator and anti-commutator.   "
},
{
<<<<<<< HEAD
  "id": "p-170",
  "level": "2",
  "url": "sec-Operations.html#p-170",
=======
  "id": "p-158",
  "level": "2",
  "url": "sec-Operations.html#p-158",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "outer product "
},
{
<<<<<<< HEAD
  "id": "p-172",
  "level": "2",
  "url": "sec-Operations.html#p-172",
=======
  "id": "p-160",
  "level": "2",
  "url": "sec-Operations.html#p-160",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "completeness relation "
},
{
  "id": "p-181",
  "level": "2",
  "url": "sec-Operations.html#p-181",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "diagonalizable "
},
{
  "id": "p-183",
  "level": "2",
  "url": "sec-Operations.html#p-183",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "density operator "
},
{
  "id": "exercise-17",
  "level": "2",
  "url": "sec-Operations.html#exercise-17",
  "type": "Checkpoint",
  "number": "1.11.1",
  "title": "",
  "body": " Find the density operator for the following state      "
},
{
  "id": "p-190",
  "level": "2",
  "url": "sec-Operations.html#p-190",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "commutator "
},
{
  "id": "p-191",
  "level": "2",
  "url": "sec-Operations.html#p-191",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "anti-commutator "
},
{
  "id": "sec1-chap2",
  "level": "1",
  "url": "sec1-chap2.html",
  "type": "Section",
  "number": "2.1",
  "title": "Introduction",
  "body": " Introduction  In the preceding chapter, we laid the groundwork for understanding quantum computing by exploring its fundamental principles and mathematical foundations. With a solid grasp of these basics, we now turn our attention to the essential building blocks of quantum computation: quantum gates and circuits. Quantum gates, akin to classical logic gates, are the fundamental operations that manipulate quantum bits (qubits). These gates perform specific transformations on qubits, enabling the execution of complex quantum algorithms. Unlike their classical counterparts, quantum gates leverage the principles of superposition and entanglement, allowing for a more powerful and intricate means of information processing.  In this chapter, we will delve into the structure and function of various quantum gates. We will start with single-qubit gates, such as the Pauli gates, the Hadamard gate, and the phase gate, which illustrate how individual qubits can be rotated and transformed. Following this, we will explore multi-qubit gates, including the Controlled-NOT (CNOT) gate and the SWAP gate, which highlight the interactions between qubits and the entanglement that underpins quantum parallelism. Understanding these gates is crucial, as they form the basis for constructing quantum circuits. A quantum circuit, composed of a sequence of quantum gates, represents a quantum algorithm or computation. By learning how to design and analyze these circuits, we gain insight into how quantum information is processed and manipulated to solve problems that are intractable for classical computers. In this chapter, we will delve into the structure and function of various quantum gates. We will start with single-qubit gates, such as the Pauli gates, the Hadamard gate, and the phase gate, which illustrate how individual qubits can be rotated and transformed. Following this, we will explore multi-qubit gates, including the Controlled-NOT (CNOT) gate and the SWAP gate, which highlight the interactions between qubits and the entanglement that underpins quantum parallelism. Understanding these gates is crucial, as they form the basis for constructing quantum circuits. A quantum circuit, composed of a sequence of quantum gates, represents a quantum algorithm or computation. By learning how to design and analyze these circuits, we gain insight into how quantum information is processed and manipulated to solve problems that are intractable for classical computers. In this chapter, our exploration will remain focused on the fundamental concepts, providing a clear and logical progression from the mathematical approach established in Chapter One. By the end of this chapter, you will have a foundational understanding of quantum gates and circuits, equipping you with the knowledge necessary to further explore the fascinating and complex world of quantum computing.  "
},
{
  "id": "sec2-chap2",
  "level": "1",
  "url": "sec2-chap2.html",
  "type": "Section",
  "number": "2.2",
  "title": "Gates",
  "body": " Gates    Hadamard gate   Hadamard gate Gate Hadamard is one of the most popular gates in quantum computing.   Hadamard gate representation in a circuit.      The Hadamard operator on one qubit can be written as   which is the Hadamard gate in Dirac notation. Hadamard operation is a rotation of the Block sphere about y axis by , followed by a rotation about axis by .   Calculate                 Pauli X gate   Pauli X gate Gate Pauli X is also labeled as , or X    X gate representation in a circuit.       Calculate                     Pauli Y gate   Pauli Y gate Gate Pauli Y is also labeled as , or Y    Y gate representation in a circuit.       Calculate                   Pauli Z   Pauli Z gate Gate Pauli Z is also labeled as , or Z    Z gate representation in a circuit.       Calculate                     Pauli I gate   Pauli I gate Gate Pauli I is also labeled as or I    I gate representation in a circuit.       Calculate                 Phase gate   Phase gate Gate Phase is written as S.   Phase gate representation in a circuit.       Calculate                     \/8 gate   \/8 gate Gate \/8 is written as T.   \/8 gate representation in a circuit.       Calculate              Previous gates aplly on single qubit. The following subsections show the multiqubit gates.     Controled-NOT  CNOT gate in the quantum context has two input qubits:  Control qbit  target qbit  This gate acts as following    CNOT gate representation in a circuit.      Check the XOR and notice this gate is for two qubits.   Obtain the Dirac notation  and   and  and  and  ( can be written as )             The gate and matrix representation are,   CNOT gate representation in a circuit.      Since   and using CNOT matrix we can cancel out some terms and reduce others to 1, such as   and we have   which is the Dirac representation for the CNOT gate.   CNOT gate representation in a circuit.      Apply CNOT to the state           Contorolled-U  Let U be a two qbit operation with a control and target qbit. This operation sets the control qbit in order U is applied to the target qbit, otherwise the target qbit is left alone.   This operation is called controlled-U operation represented by   CU representation in a circuit     CU operator as Dirac notation      Contorolled-Z  The unitary matrix in the computational basis is,   CZ representation in a circuit       Obtain                    "
},
{
<<<<<<< HEAD
  "id": "p-197",
  "level": "2",
  "url": "sec2-chap2.html#p-197",
=======
  "id": "p-166",
  "level": "2",
  "url": "sec2-chap2.html#p-166",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Hadamard gate "
},
{
  "id": "fig-HgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-HgateSimple_1",
  "type": "Figure",
  "number": "2.2.1",
  "title": "",
  "body": " Hadamard gate representation in a circuit.    "
},
{
  "id": "exe-HGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-HGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.2",
  "title": "",
  "body": " Calculate             "
},
{
<<<<<<< HEAD
  "id": "p-202",
  "level": "2",
  "url": "sec2-chap2.html#p-202",
=======
  "id": "p-171",
  "level": "2",
  "url": "sec2-chap2.html#p-171",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Pauli X gate "
},
{
  "id": "fig-XgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-XgateSimple_1",
  "type": "Figure",
  "number": "2.2.3",
  "title": "",
  "body": " X gate representation in a circuit.    "
},
{
  "id": "exe-XGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-XGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.4",
  "title": "",
  "body": " Calculate                 "
},
{
<<<<<<< HEAD
  "id": "p-205",
  "level": "2",
  "url": "sec2-chap2.html#p-205",
=======
  "id": "p-174",
  "level": "2",
  "url": "sec2-chap2.html#p-174",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Pauli Y gate "
},
{
  "id": "fig-ygateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-ygateSimple_1",
  "type": "Figure",
  "number": "2.2.5",
  "title": "",
  "body": " Y gate representation in a circuit.    "
},
{
  "id": "exe-YGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-YGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.6",
  "title": "",
  "body": " Calculate               "
},
{
<<<<<<< HEAD
  "id": "p-208",
  "level": "2",
  "url": "sec2-chap2.html#p-208",
=======
  "id": "p-177",
  "level": "2",
  "url": "sec2-chap2.html#p-177",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Pauli Z gate "
},
{
  "id": "fig-zgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-zgateSimple_1",
  "type": "Figure",
  "number": "2.2.7",
  "title": "",
  "body": " Z gate representation in a circuit.    "
},
{
  "id": "exe-ZGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-ZGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.8",
  "title": "",
  "body": " Calculate                 "
},
{
<<<<<<< HEAD
  "id": "p-211",
  "level": "2",
  "url": "sec2-chap2.html#p-211",
=======
  "id": "p-180",
  "level": "2",
  "url": "sec2-chap2.html#p-180",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Pauli I gate "
},
{
  "id": "fig-IgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-IgateSimple_1",
  "type": "Figure",
  "number": "2.2.9",
  "title": "",
  "body": " I gate representation in a circuit.    "
},
{
  "id": "exe-IGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-IGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.10",
  "title": "",
  "body": " Calculate             "
},
{
<<<<<<< HEAD
  "id": "p-214",
  "level": "2",
  "url": "sec2-chap2.html#p-214",
=======
  "id": "p-183",
  "level": "2",
  "url": "sec2-chap2.html#p-183",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Phase gate "
},
{
  "id": "fig-SgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-SgateSimple_1",
  "type": "Figure",
  "number": "2.2.11",
  "title": "",
  "body": " Phase gate representation in a circuit.    "
},
{
  "id": "exe-SGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-SGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.12",
  "title": "",
  "body": " Calculate                 "
},
{
<<<<<<< HEAD
  "id": "p-217",
  "level": "2",
  "url": "sec2-chap2.html#p-217",
=======
  "id": "p-186",
  "level": "2",
  "url": "sec2-chap2.html#p-186",
>>>>>>> 5713a2ebdff2310a2ffc7b5893bd56c983a4152b
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "\/8 gate "
},
{
  "id": "fig-TgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-TgateSimple_1",
  "type": "Figure",
  "number": "2.2.13",
  "title": "",
  "body": " \/8 gate representation in a circuit.    "
},
{
  "id": "exe-TGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-TGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.14",
  "title": "",
  "body": " Calculate             "
},
{
  "id": "fig-CNOTgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-CNOTgateSimple_1",
  "type": "Figure",
  "number": "2.2.15",
  "title": "",
  "body": " CNOT gate representation in a circuit.    "
},
{
  "id": "exe-CNOTGapllicationQbits1",
  "level": "2",
  "url": "sec2-chap2.html#exe-CNOTGapllicationQbits1",
  "type": "Checkpoint",
  "number": "2.2.16",
  "title": "",
  "body": " Obtain the Dirac notation  and   and  and  and  ( can be written as )            "
},
{
  "id": "fig-CNOTgateSimple_2",
  "level": "2",
  "url": "sec2-chap2.html#fig-CNOTgateSimple_2",
  "type": "Figure",
  "number": "2.2.17",
  "title": "",
  "body": " CNOT gate representation in a circuit.    "
},
{
  "id": "fig-CNOTgateSimple_3",
  "level": "2",
  "url": "sec2-chap2.html#fig-CNOTgateSimple_3",
  "type": "Figure",
  "number": "2.2.18",
  "title": "",
  "body": " CNOT gate representation in a circuit.    "
},
{
  "id": "exe-CNOTGapllicationQbits4",
  "level": "2",
  "url": "sec2-chap2.html#exe-CNOTGapllicationQbits4",
  "type": "Checkpoint",
  "number": "2.2.19",
  "title": "",
  "body": " Apply CNOT to the state       "
},
{
  "id": "fig-CUgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-CUgateSimple_1",
  "type": "Figure",
  "number": "2.2.20",
  "title": "",
  "body": " CU representation in a circuit    "
},
{
  "id": "fig-CZgateSimple_1",
  "level": "2",
  "url": "sec2-chap2.html#fig-CZgateSimple_1",
  "type": "Figure",
  "number": "2.2.21",
  "title": "",
  "body": " CZ representation in a circuit    "
},
{
  "id": "exe-CZGapllicationQbits",
  "level": "2",
  "url": "sec2-chap2.html#exe-CZGapllicationQbits",
  "type": "Checkpoint",
  "number": "2.2.22",
  "title": "",
  "body": " Obtain                 "
},
{
  "id": "sec3-chap2",
  "level": "1",
  "url": "sec3-chap2.html",
  "type": "Section",
  "number": "2.3",
  "title": "Circuits",
  "body": " Circuits    NOT gate  This model is inspired by the classical gates with their truth table.   NOT logicall classical gate representation         AND gate  AND logical classical gate and corresponding truth table.   AND logicall classical gate logicall classical gate representation         Reversible and Nonreversible gate  Since QC is related to a theory of reversible computing, we note that the NOT gate is reversible while the AND gate is not.   Non-reversible AND gate representation     With the circuit in the fig. 2.3.3, we can simulate a non-reversible gate, besides, we keep a copy of the inputs and add of the operation, after it adds previous result to . We fix and obtain a non-reversible AND gate. Where represents the logical exclusive-OR operation, which it is the same addition modulo two. Then, we can obtain a reversible version of the circuit if we replace the irreversible parts with their reversible counterparts.    Controlled-NOT gate representation     "
},
{
  "id": "fig-NOTcgategateSimple_1",
  "level": "2",
  "url": "sec3-chap2.html#fig-NOTcgategateSimple_1",
  "type": "Figure",
  "number": "2.3.1",
  "title": "",
  "body": " NOT logicall classical gate representation    "
},
{
  "id": "fig-ANDcgatecgategateSimple_1",
  "level": "2",
  "url": "sec3-chap2.html#fig-ANDcgatecgategateSimple_1",
  "type": "Figure",
  "number": "2.3.2",
  "title": "",
  "body": " AND logicall classical gate logicall classical gate representation    "
},
{
  "id": "fig-NonrANDgategateSimple_1",
  "level": "2",
  "url": "sec3-chap2.html#fig-NonrANDgategateSimple_1",
  "type": "Figure",
  "number": "2.3.3",
  "title": "",
  "body": " Non-reversible AND gate representation    "
},
{
  "id": "fig-CCNOTcgategateSimple_1",
  "level": "2",
  "url": "sec3-chap2.html#fig-CCNOTcgategateSimple_1",
  "type": "Figure",
  "number": "2.3.4",
  "title": "",
  "body": " Controlled-NOT gate representation    "
},
{
  "id": "sec1-chap3",
  "level": "1",
  "url": "sec1-chap3.html",
  "type": "Section",
  "number": "3.1",
  "title": "Grover’s Algorithm",
  "body": " Grover's Algorithm    Classical search algorithms are fundamental techniques used in computer science to locate a specific item within a collection of items. Common approaches include linear search, where each item is checked sequentially until the target is found, and binary search, which efficiently narrows down the search range in a sorted array by repeatedly dividing it in half. These methods are crucial in various applications, from database retrieval to optimization problems, as they determine how quickly and efficiently data can be accessed and processed. However, classical search often requires significant time and resources, especially with large datasets. Quantum computing has the potential to revolutionize search algorithms through methods like Grover's algorithm, which can search an unsorted database quadratically faster than classical algorithms, offering a profound improvement in speed and efficiency for large-scale search problems.  To implement Grover's algorithm, we need unitary matrix , written as . This matrix works as a black box as following   The XOR operartion is    diffusion gate is an operator given by  Household transform is is a linear algebra technique often used to construct quantum operations that reflect a quantum state about a certain axis or state, which is a crucial step in many quantum algorithms, including Grover's algorithm. By applying a series of these transformations, one can systematically manipulate and amplify the amplitude of the desired state while diminishing the amplitudes of the undesired ones, ultimately leading to a more efficient search process. This method contributes to the algorithm's overall quadratic speedup compared to classical search methods.  Now, we implement Grover's algorithm for the following example    We prose a random vector , and tries to find the expected factor.   1. Consider you have the following data    Representation of values       2. Calculate the average   3. Invert each element aorund the average by defining   We calculate the units away, , from the average, , for each    4.a define   and calculate   The inversion about the average calculates the units away, , from the average, , for each .   4.b Plot the data      Representation of values      The last operation, has the following representation in terms of matrices, where where is the matrix for the average. It means . As follows, This is a state where each amplitude is the average of all the amplitudes.   5. Invert amplitudes about the average.    The item (4).b and eq. (3.1.11) show same results, the second report implies linear algebra operations.  This example emphasizes on invert amplitudes about the mean; however, Grover's algorithm requires phase inversion. The following example explains the step.      Consider the information from the example 3.1.1. We have the same vector.    To apply the phase inversion about the average, which requires the function,   and   which is usually shown such as   where is an $U_f$ aka oracle. This oracle shifts the phase of the solution, and highlights the solutions to the search problem.   We will take the vector   And suppose we are looking for the second input, it means x=x_2=w  is the winner, it is oul goal.    \\ Now we apply   Representation of the values. The horizontal line is the new average      and calculate    Representation of the values. The horizontal line is the new average      and calculate   We can see how the amplitude for the second element increases.   We showed how this search algorithm works, and it is clear that we will get the second element in the list as the most probable output.    This part shows the Grover's algorithm in bracket notation.  This algorithm enables this search method to be speed up to operations. With this algorithm \"searching an unsorted database\" with elements in time. Classical algorithm needs on average time. The goal is find , given an oracle with   "
},
{
  "id": "p-212",
  "level": "2",
  "url": "sec1-chap3.html#p-212",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Classical search "
},
{
  "id": "p-213",
  "level": "2",
  "url": "sec1-chap3.html#p-213",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "unitary matrix "
},
{
  "id": "p-215",
  "level": "2",
  "url": "sec1-chap3.html#p-215",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "diffusion gate Household transform "
},
{
  "id": "example-4",
  "level": "2",
  "url": "sec1-chap3.html#example-4",
  "type": "Example",
  "number": "3.1.1",
  "title": "",
  "body": " We prose a random vector , and tries to find the expected factor.   1. Consider you have the following data    Representation of values       2. Calculate the average   3. Invert each element aorund the average by defining   We calculate the units away, , from the average, , for each    4.a define   and calculate   The inversion about the average calculates the units away, , from the average, , for each .   4.b Plot the data      Representation of values      The last operation, has the following representation in terms of matrices, where where is the matrix for the average. It means . As follows, This is a state where each amplitude is the average of all the amplitudes.   5. Invert amplitudes about the average.    The item (4).b and eq. (3.1.11) show same results, the second report implies linear algebra operations.  This example emphasizes on invert amplitudes about the mean; however, Grover's algorithm requires phase inversion. The following example explains the step.  "
},
{
  "id": "example-5",
  "level": "2",
  "url": "sec1-chap3.html#example-5",
  "type": "Example",
  "number": "3.1.4",
  "title": "",
  "body": "  Consider the information from the example 3.1.1. We have the same vector.    To apply the phase inversion about the average, which requires the function,   and   which is usually shown such as   where is an $U_f$ aka oracle. This oracle shifts the phase of the solution, and highlights the solutions to the search problem.   We will take the vector   And suppose we are looking for the second input, it means x=x_2=w  is the winner, it is oul goal.    \\ Now we apply   Representation of the values. The horizontal line is the new average      and calculate    Representation of the values. The horizontal line is the new average      and calculate   We can see how the amplitude for the second element increases.   We showed how this search algorithm works, and it is clear that we will get the second element in the list as the most probable output.  "
},
{
  "id": "sec2-chap3",
  "level": "1",
  "url": "sec2-chap3.html",
  "type": "Section",
  "number": "3.2",
  "title": "Shor’s Algorithm",
  "body": " Shor's Algorithm  Text of section.  "
},
{
  "id": "index-1",
  "level": "1",
  "url": "index-1.html",
  "type": "Index",
  "number": "",
  "title": "Index",
  "body": " Index   "
},
{
  "id": "colophon-2",
  "level": "1",
  "url": "colophon-2.html",
  "type": "Colophon",
  "number": "",
  "title": "Colophon",
  "body": " This book was authored in PreTeXt .  "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
